\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\citation{ogawa1990brain}
\citation{shmuel2002sustained}
\citation{huettel2004functional}
\citation{Kornysheva2014}
\citation{Kornysheva2014}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Classification approach}{2}{section.1}}
\newlabel{sec:classification}{{1}{2}{Classification approach\relax }{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}K-Nearest-Neighbors (KNN) classifier}{2}{subsection.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Example of KNN classification. The test sample (green circle) should be classified either to the first class of blue squares or to the second class of red triangles. If K = 3 (solid line circle) it is assigned to the second class because there are 2 triangles and only 1 square inside the inner circle. If K = 5 (dashed line circle) it is assigned to the first class (3 squares vs. 2 triangles inside the outer circle). Credit to https://en.wikipedia.org/wiki/K-nearest\_neighbors\_algorithm\#/media/File:KnnClassification.svg\relax }}{2}{figure.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:knn_example}{{1.1}{2}{Example of KNN classification. The test sample (green circle) should be classified either to the first class of blue squares or to the second class of red triangles. If K = 3 (solid line circle) it is assigned to the second class because there are 2 triangles and only 1 square inside the inner circle. If K = 5 (dashed line circle) it is assigned to the first class (3 squares vs. 2 triangles inside the outer circle). Credit to https://en.wikipedia.org/wiki/K-nearest\_neighbors\_algorithm\#/media/File:KnnClassification.svg\relax \relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Cross-validation}{2}{subsection.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces KNN: Estimated distribution (probability densities) of the average accuracy of KNN classifier w.r.t different levels of signal noise ratio (SNR). We test the presence of the main effect against pure noise (bold blue curve). The critical value (red vertical bar) is chosen as $95$ percentile of H0 distribution (bold blue curve). The power is the rate of rejection of H0 in the presence of the main effect. The legend on the plot shows the SNR and power of the statistic test. The power reaches level of $93\%$ at SNR=$0.15$.\relax }}{3}{figure.caption.4}}
\newlabel{fig:knn convergence}{{1.2}{3}{KNN: Estimated distribution (probability densities) of the average accuracy of KNN classifier w.r.t different levels of signal noise ratio (SNR). We test the presence of the main effect against pure noise (bold blue curve). The critical value (red vertical bar) is chosen as $95$ percentile of H0 distribution (bold blue curve). The power is the rate of rejection of H0 in the presence of the main effect. The legend on the plot shows the SNR and power of the statistic test. The power reaches level of $93\%$ at SNR=$0.15$.\relax \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Factorial pattern analysis of fMRI data}{3}{subsection.1.3}}
\citation{Kornysheva2014}
\citation{Kornysheva2014}
\citation{Kornysheva2014}
\citation{Kornysheva2014}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces KNN: Testing main effect (circle markers) against all possible combinations of other effects (without markers). \newline  {\bf  (a)} Note that as soon as some interaction is introduced the expected value of the classification accuracy increases. This is because interaction allows to discriminate different conditions even if no main effect present.\newline  {\bf  (b)} The distribution of the statistic is not invariant to presence of other effects. 0/1 in the legend codes absence/presence of two main effects and interaction between them. Critical value is given by 95\% percentile of H0 distribution. The power is computed as portion of points generated from H1 distribution that are above the critical value. For example, ``101 / Power = 0.852'' corresponds to H1 s.t. there is no main effect S but there are main effect T and interaction between S and T. H0 in this case is ``001'', i.e. only interaction is present.\relax }}{4}{figure.caption.5}}
\newlabel{fig:knn drift}{{1.3}{4}{KNN: Testing main effect (circle markers) against all possible combinations of other effects (without markers). \newline {\bf (a)} Note that as soon as some interaction is introduced the expected value of the classification accuracy increases. This is because interaction allows to discriminate different conditions even if no main effect present.\newline {\bf (b)} The distribution of the statistic is not invariant to presence of other effects. 0/1 in the legend codes absence/presence of two main effects and interaction between them. Critical value is given by 95\% percentile of H0 distribution. The power is computed as portion of points generated from H1 distribution that are above the critical value. For example, ``101 / Power = 0.852'' corresponds to H1 s.t. there is no main effect S but there are main effect T and interaction between S and T. H0 in this case is ``001'', i.e. only interaction is present.\relax \relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Main effect detection}{4}{subsection.1.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Two factors have 3 levels: S1,S2,S3 and T1,T2,T3. All possible combination of levels result in 9 measured activation patterns ({\bf  A}). Double cross-validation allows to decode the main effects ({\bf  B} and {\bf  C}) independently from interaction. Mean subtraction for both factors allows to destroy their main effects and detect only interaction ({\bf  D}). The plot is by~\cite  {Kornysheva2014}\relax }}{5}{figure.caption.6}}
\newlabel{fig:patterns}{{1.4}{5}{Two factors have 3 levels: S1,S2,S3 and T1,T2,T3. All possible combination of levels result in 9 measured activation patterns ({\bf A}). Double cross-validation allows to decode the main effects ({\bf B} and {\bf C}) independently from interaction. Mean subtraction for both factors allows to destroy their main effects and detect only interaction ({\bf D}). The plot is by~\cite {Kornysheva2014}\relax \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Interaction detection}{5}{subsection.1.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Results and conclusions}{5}{subsection.1.6}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Discussion}{5}{section.2}}
\bibstyle{unsrt}
\bibdata{ref}
\bibcite{ogawa1990brain}{1}
\bibcite{shmuel2002sustained}{2}
\bibcite{huettel2004functional}{3}
\bibcite{Kornysheva2014}{4}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Double cross validation for detecting the main effect of the spatial factor. Suppose one tests a classifier on patterns that have the temporal factor level of Tn (marked by word test on the plot) and originate from run $i$ (green box on the plot). Then the classifier should be trained on the rest of the patterns except the patterns with the same temporal level Tn or from run $i$ (blue box on the plot).\relax }}{6}{figure.caption.7}}
\newlabel{fig:2xval}{{1.5}{6}{Double cross validation for detecting the main effect of the spatial factor. Suppose one tests a classifier on patterns that have the temporal factor level of Tn (marked by word test on the plot) and originate from run $i$ (green box on the plot). Then the classifier should be trained on the rest of the patterns except the patterns with the same temporal level Tn or from run $i$ (blue box on the plot).\relax \relax }{figure.caption.7}{}}
\newlabel{fig:2xval for main effect}{{1.6a}{6}{Testing the main effect for the first factor (circle markers) against all possible combinations (without markers) with double cross-validation. The distributions only depend on the presence of the main effect. Note that there is no drift as in \autoref {fig:knn drift}.\relax \relax }{figure.caption.8}{}}
\newlabel{sub@fig:2xval for main effect}{{a}{6}{Testing the main effect for the first factor (circle markers) against all possible combinations (without markers) with double cross-validation. The distributions only depend on the presence of the main effect. Note that there is no drift as in \autoref {fig:knn drift}.\relax \relax }{figure.caption.8}{}}
\newlabel{fig:test interaction}{{1.6b}{6}{Testing interaction (circle markers) against all possible combinations (without markers). The distributions only depend on the presence of the interaction.\relax \relax }{figure.caption.8}{}}
\newlabel{sub@fig:test interaction}{{b}{6}{Testing interaction (circle markers) against all possible combinations (without markers). The distributions only depend on the presence of the interaction.\relax \relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Detection of main effects (a) and interaction (b). For the legend description see \autoref  {fig:knn drift}.\relax }}{6}{figure.caption.8}}
